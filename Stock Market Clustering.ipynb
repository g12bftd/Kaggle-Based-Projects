{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given 27 different companies in the SP500, we will extract their stock price data directly from Yahoo Finance. The objective is to use the KMeans algorithm to categorize these companies into 5 clusters, by the magnitude of the changes in opening and closing stock price between Jan 1st 2015 and Jan 1st 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_dict = {\n",
    "    \"Amazon\": \"AMZN\",\n",
    "    \"Apple\": \"AAPL\",\n",
    "    \"Walgreen\": \"WBA\",\n",
    "    \"Northrop Grumman\": \"NOC\",\n",
    "    \"Boeing\": \"BA\",\n",
    "    \"Lockheed Martin\": \"LMT\",\n",
    "    \"McDonalds\": \"MCD\",\n",
    "    \"Intel\": \"INTC\",\n",
    "    \"Navistar\": \"NAV\",\n",
    "    \"IBM\": \"IBM\",\n",
    "    \"Texas Instruments\": \"TXN\",\n",
    "    \"MasterCard\": \"MA\",\n",
    "    \"Microsoft\": \"MSFT\",\n",
    "    \"General Electrics\": \"GE\",\n",
    "    \"American Express\": \"AXP\",\n",
    "    \"Pepsi\": \"PEP\",\n",
    "    \"Coca Cola\": \"KO\",\n",
    "    \"Johnson & Johnson\": \"JNJ\",\n",
    "    \"Toyota\": \"TM\",\n",
    "    \"Honda\": \"HMC\",\n",
    "    \"Mitsubishi\": \"MSBHF\",\n",
    "    \"Sony\": \"SNE\",\n",
    "    \"Exxon\": \"XOM\",\n",
    "    \"Chevron\": \"CVX\",\n",
    "    \"Valero Energy\": \"VLO\",\n",
    "    \"Ford\": \"F\",\n",
    "    \"Bank of America\": \"BAC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"yahoo\"\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2020-01-01\"\n",
    "data = data.DataReader(list(companies_dict.values()), data_source,start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_open = np.array(data[\"Open\"]).T\n",
    "stock_close = np.array(data[\"Close\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_open_diff = stock_close - stock_open\n",
    "sum_of_diff = np.sum(close_open_diff, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(companies_dict)):\n",
    "    print(\"Company:{}, Change:{}\".format(data[\"High\"].columns[i], sum_of_diff[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 3, ncols = 9, figsize = (50, 25))\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "fig.suptitle(\"Daily Stock Opening Prices\", fontsize = 45)\n",
    "\n",
    "for ax, value in zip(axes.flatten(), companies_dict.values()):\n",
    "    lp = sns.lineplot(data = data[\"Open\"][value], ax = ax)\n",
    "    lp.axes.set_title(value, fontsize = 50)\n",
    "    lp.set_xlabel(\"Date\", fontsize = 30)\n",
    "    lp.set_ylabel(\"Opening Price($)\", fontsize = 30)\n",
    "    lp.tick_params(labelsize = 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are just here to provide an idea of the general trend of each stock. It must be noted that the y-axes are DIFFERENT for each stock and should not be compared. Rather, we want to have a sense of the general stock price movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.title(\"Apple\", fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"Date\", fontsize = 20)\n",
    "plt.ylabel(\"Change in Stock Price between Open and Close($)\", fontsize = 20)\n",
    "plt.plot(close_open_diff[1])\n",
    "\n",
    "plt.subplot(1, 2, 2, sharey = ax1)\n",
    "plt.title(\"Amazon\", fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"Date\", fontsize = 20)\n",
    "plt.ylabel(\"Change in Stock Price between Open and Close ($)\", fontsize = 20)\n",
    "plt.plot(close_open_diff[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection of the plots above, the stock prices for Amazon and Apple are on different scales. This can be generalized for all 27 stocks. Therefore, normalization or standardization is called for, if we want to model stock price using machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "norm_movements = normalizer.fit_transform(close_open_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_movements.min())\n",
    "print(norm_movements.max())\n",
    "print(norm_movements.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.title(\"Apple\", fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"Date\", fontsize = 20)\n",
    "plt.ylabel(\"Change in Stock Price between Open and Close($)\", fontsize = 20)\n",
    "plt.plot(norm_movements[1])\n",
    "\n",
    "plt.subplot(1, 2, 2, sharey = ax1)\n",
    "plt.title(\"Amazon\", fontsize = 20)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xlabel(\"Date\", fontsize = 20)\n",
    "plt.ylabel(\"Change in Stock Price between Open and Close ($)\", fontsize = 20)\n",
    "plt.plot(norm_movements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stock price changes are now on the same scale and meaningful comparisons can be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "normalizer = Normalizer()\n",
    "kmeans = KMeans(n_clusters = 5, max_iter = 1000, random_state = 1)\n",
    "\n",
    "pipeline = make_pipeline(normalizer, kmeans)\n",
    "\n",
    "pipeline.fit(close_open_diff)\n",
    "predictions = pipeline.predict(close_open_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({\"Cluster\":predictions, \"companies\":list(companies_dict)})\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_movements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "pca_data = PCA(n_components = 2)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 5, max_iter = 1000)\n",
    "\n",
    "pipeline = make_pipeline(normalizer, pca_data, kmeans)\n",
    "\n",
    "pipeline.fit(close_open_diff)\n",
    "\n",
    "preditions = pipeline.predict(close_open_diff)\n",
    "\n",
    "predict2_df = pd.DataFrame({\"Cluster\":predictions, \"companies\":list(companies_dict)})\n",
    "predict2_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Data Dimensionality\n",
    "pca_data = PCA(n_components = 2).fit_transform(norm_movements)\n",
    "\n",
    "# Define the mesh step size\n",
    "h = 0.002\n",
    "\n",
    "# Plot decision boundary\n",
    "x_min, x_max = pca_data[:,0].min()-1, pca_data[:, 0].max() + 1\n",
    "y_min, y_max = pca_data[:,1].min()-1, pca_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Label each point in the mesh using our model\n",
    "kpredictions = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Plot results by color\n",
    "kpredictions = kpredictions.reshape(xx.shape)\n",
    "cmap = plt.cm.Paired\n",
    "plt.clf()\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(kpredictions, interpolation = \"nearest\", extent = (xx.min(), xx.max(), yy.min(), yy.max()), \n",
    "           cmap = cmap, aspect = \"auto\", origin = \"lower\")\n",
    "plt.plot(pca_data[:, 0], pca_data[:, 1], \"k.\", markersize = 5)\n",
    "\n",
    "# Plot the centroid of each cluster (white X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker = \"x\", s = 169, \n",
    "            linewidths = 3, color = \"w\", zorder = 10)\n",
    "plt.title(\"K-Means clustering results on stock market price movements (PCA-Reduced Data)\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Clusters\":predictions, \"Companies\":list(companies_dict)}).sort_values(by=[\"Clusters\"], axis = 0)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
